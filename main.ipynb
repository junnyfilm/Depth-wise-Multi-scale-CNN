{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c6d9753-b2b9-4c73-b891-7835f8a89dbc",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d049768-9508-47fd-b7fc-09c406023815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, metrics\n",
    "\n",
    "import seaborn as sn\n",
    "from tqdm.notebook import tqdm  # Assuming you want the notebook version\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch import topk\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as Fv\n",
    "\n",
    "# For Jupyter Notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf3056-ca95-4b81-a4a7-b7824d0d976b",
   "metadata": {},
   "source": [
    "### data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c0db82-adaa-48f0-a602-52540b39771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('indiv_1.pickle', 'rb') as f:\n",
    "    indiv_1 = pickle.load(f)\n",
    "with open('label1.pickle', 'rb') as f:\n",
    "    label1 = pickle.load(f)\n",
    "with open('indiv_2.pickle', 'rb') as f:\n",
    "    indiv_2 = pickle.load(f)\n",
    "with open('label2.pickle', 'rb') as f:\n",
    "    label2 = pickle.load(f)\n",
    "with open('indiv_3.pickle', 'rb') as f:\n",
    "    indiv_3 = pickle.load(f)\n",
    "with open('label3.pickle', 'rb') as f:\n",
    "    label3 = pickle.load(f)\n",
    "with open('indiv_4.pickle', 'rb') as f:\n",
    "    indiv_4 = pickle.load(f)\n",
    "with open('label4.pickle', 'rb') as f:\n",
    "    label4 = pickle.load(f)\n",
    "with open('indiv_5.pickle', 'rb') as f:\n",
    "    indiv_5 = pickle.load(f)\n",
    "with open('label5.pickle', 'rb') as f:\n",
    "    label5 = pickle.load(f)\n",
    "with open('indiv_6.pickle', 'rb') as f:\n",
    "    indiv_6 = pickle.load(f)\n",
    "with open('label6.pickle', 'rb') as f:\n",
    "    label6 = pickle.load(f)\n",
    "with open('indiv_7.pickle', 'rb') as f:\n",
    "    indiv_7 = pickle.load(f)\n",
    "with open('indiv_8.pickle', 'rb') as f:\n",
    "    indiv_8 = pickle.load(f)\n",
    "with open('label7.pickle', 'rb') as f:\n",
    "    label7 = pickle.load(f)\n",
    "with open('label8.pickle', 'rb') as f:\n",
    "    label8 = pickle.load(f)\n",
    "    \n",
    "      \n",
    "with open('train_set12345.pickle', 'rb') as f:\n",
    "    train_set12345 = pickle.load(f)\n",
    "with open('train_set12346.pickle', 'rb') as f:\n",
    "    train_set12346 = pickle.load(f)\n",
    "with open('train_set12356.pickle', 'rb') as f:\n",
    "    train_set12356 = pickle.load(f)\n",
    "with open('train_set12456.pickle', 'rb') as f:\n",
    "    train_set12456 = pickle.load(f)\n",
    "with open('train_set13456.pickle', 'rb') as f:\n",
    "    train_set13456 = pickle.load(f)\n",
    "with open('train_set23456.pickle', 'rb') as f:\n",
    "    train_set23456 = pickle.load(f)\n",
    "with open('train_set123456.pickle', 'rb') as f:\n",
    "    train_set123456 = pickle.load(f)    \n",
    "\n",
    "with open('train_label12345.pickle', 'rb') as f:\n",
    "    train_label12345 = pickle.load(f)\n",
    "with open('train_label12346.pickle', 'rb') as f:\n",
    "    train_label12346 = pickle.load(f)\n",
    "with open('train_label12356.pickle', 'rb') as f:\n",
    "    train_label12356 = pickle.load(f)\n",
    "with open('train_label12456.pickle', 'rb') as f:\n",
    "    train_label12456 = pickle.load(f)\n",
    "with open('train_label13456.pickle', 'rb') as f:\n",
    "    train_label13456 = pickle.load(f)\n",
    "with open('train_label23456.pickle', 'rb') as f:\n",
    "    train_label23456 = pickle.load(f)\n",
    "with open('train_label123456.pickle', 'rb') as f:\n",
    "    train_label123456 = pickle.load(f)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6adad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import loaders,tripletloader\n",
    "from custom_dataset import customdataset_ts\n",
    "from model import Feature_extractor1,\n",
    "\n",
    "from train import train\n",
    "from pseudo_train import train_target\n",
    "from test import test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2321736",
   "metadata": {},
   "source": [
    "### loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c142e4ec-505f-454a-af4a-c0afdcefa3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train loader\n",
    "train_set, test_set, train_label, test_label = train_test_split(train_set123456, train_label123456, train_size=0.8, random_state=1)\n",
    "train_loader123456,valid_loader123456,test_loader7=loaders(train_set123456, train_label123456,indiv_7,label7)\n",
    "triplet_loader123456=tripletloader(train_set123456,train_label123456)\n",
    "#test loader and loader for domain adaptation\n",
    "testloader7 = DataLoader(customdataset_ts(indiv_7), batch_size=1, shuffle=False, drop_last=False )\n",
    "coral_testloader7 = DataLoader(testdataset7, batch_size=32, shuffle=True, drop_last=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff57c03-578f-4b79-8179-4008bfc963bd",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cfe508b-1c0e-4fc5-9ea2-18535d1e6d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor1 = Feature_extractor().to(device)\n",
    "feature_extractor2 = Feature_extractor().to(device)\n",
    "feature_extractor3 = Feature_extractor().to(device)\n",
    "def models(pretrained=False, **kwargs):\n",
    "    backbone = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return backbone\n",
    "backbone = models().to(device)\n",
    "seblock=SE_Block().to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "        {'params': feature_extractor1.parameters()},\n",
    "        {'params': feature_extractor2.parameters()},\n",
    "        {'params': feature_extractor3.parameters()},\n",
    "        {'params': backbone.parameters()},    \n",
    "        ], lr= 0.00005)\n",
    "batch_size = 32\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "best_acc=0\n",
    "acc_list1 = []\n",
    "step = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d9a8a76-7424-4032-9191-35681ba151d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "[3168/29783 (11%)]\t pseudo Loss: 2.120978\n",
      "[6368/29783 (21%)]\t pseudo Loss: 1.761515\n",
      "\n",
      "Accuracy: 6528.0/7935 (82.2684%)\n",
      "\n",
      "Epoch: 1\n",
      "[3168/29783 (11%)]\t pseudo Loss: 0.832907\n",
      "[6368/29783 (21%)]\t pseudo Loss: 0.803008\n",
      "\n",
      "Accuracy: 7217.0/7935 (90.9515%)\n",
      "\n",
      "Epoch: 2\n",
      "[3168/29783 (11%)]\t pseudo Loss: 0.542550\n",
      "[6368/29783 (21%)]\t pseudo Loss: 0.509844\n",
      "\n",
      "Accuracy: 7917.0/7935 (99.7732%)\n",
      "\n",
      "Epoch: 3\n",
      "[3168/29783 (11%)]\t pseudo Loss: 0.391226\n",
      "[6368/29783 (21%)]\t pseudo Loss: 0.601363\n",
      "\n",
      "Accuracy: 7933.0/7935 (99.9748%)\n",
      "\n",
      "Epoch: 4\n",
      "[3168/29783 (11%)]\t pseudo Loss: 0.366231\n",
      "[6368/29783 (21%)]\t pseudo Loss: 0.362410\n",
      "\n",
      "Accuracy: 7932.0/7935 (99.9622%)\n",
      "\n",
      "Epoch: 5\n",
      "[3168/29783 (11%)]\t pseudo Loss: 0.327619\n",
      "[6368/29783 (21%)]\t pseudo Loss: 0.346713\n",
      "\n",
      "Accuracy: 7934.0/7935 (99.9874%)\n",
      "\n",
      "Epoch: 6\n",
      "[3168/29783 (11%)]\t pseudo Loss: 0.211689\n",
      "[6368/29783 (21%)]\t pseudo Loss: 0.286228\n",
      "\n",
      "Accuracy: 7933.0/7935 (99.9748%)\n",
      "\n",
      "Epoch: 7\n",
      "[3168/29783 (11%)]\t pseudo Loss: 0.240602\n",
      "[6368/29783 (21%)]\t pseudo Loss: 0.247913\n",
      "\n",
      "Accuracy: 7934.0/7935 (99.9874%)\n",
      "\n",
      "Epoch: 8\n",
      "[3168/29783 (11%)]\t pseudo Loss: 0.191907\n",
      "[6368/29783 (21%)]\t pseudo Loss: 0.483301\n",
      "\n",
      "Accuracy: 7933.0/7935 (99.9748%)\n",
      "\n",
      "Epoch: 9\n",
      "[3168/29783 (11%)]\t pseudo Loss: 0.475055\n",
      "[6368/29783 (21%)]\t pseudo Loss: 0.340212\n",
      "\n",
      "Accuracy: 7935.0/7935 (100.0000%)\n",
      "\n",
      "Best valid Acc: 100.0\n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    if epoch > -1:\n",
    "        train_target(feature_extractor1,feature_extractor2,feature_extractor3,backbone, criterion, train_loader123456, coral_testloader7,triplet_loader123456,optimizer, epoch,step)\n",
    "    else:\n",
    "        train(feature_extractor1,feature_extractor2,feature_extractor3,backbone, criterion, train_loader123456, test_loader7,triplet_loader123456,optimizer, epoch,step)\n",
    "    acc,predlist,realist=test(feature_extractor1,feature_extractor2,feature_extractor3,backbone,test_loader7)\n",
    "    acc_list1.append(acc)\n",
    "    if acc > best_acc:\n",
    "        best_model_feature_extractor1 = copy.deepcopy(feature_extractor1.state_dict())\n",
    "        best_model_feature_extractor2 = copy.deepcopy(feature_extractor2.state_dict())\n",
    "        best_model_feature_extractor3 = copy.deepcopy(feature_extractor3.state_dict())\n",
    "        best_model_convnet = copy.deepcopy(backbone.state_dict())\n",
    "\n",
    "        feature_extractor1.load_state_dict(best_model_feature_extractor1)\n",
    "        feature_extractor2.load_state_dict(best_model_feature_extractor2)\n",
    "        feature_extractor3.load_state_dict(best_model_feature_extractor3)\n",
    "        SimpleConvmodel.load_state_dict(best_model_convnet)\n",
    "\n",
    "        torch.save(feature_extractor1.state_dict(), 'total_model5_test_7_feature_extractor1.pt')\n",
    "        torch.save(feature_extractor2.state_dict(), 'total_model5_test_7_feature_extractor2.pt')\n",
    "        torch.save(feature_extractor3.state_dict(), 'total_model5_test_7_feature_extractor3.pt')\n",
    "        torch.save(SimpleConvmodel.state_dict(), 'total_model5_test_7_backbone.pt')\n",
    "        np.savetxt(\"save.txt\",predlist , fmt='%d', delimiter=',')\n",
    "        # print('==> best model saved - %d / %.1f'%(epoch, acc))\n",
    "        best_acc=acc\n",
    "\n",
    "print('Best valid Acc: %.1f' %(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1743bcb2-95c1-454b-a7de-d9aa94eae969",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedv1=[]\n",
    "feature_extractor1.eval()\n",
    "feature_extractor2.eval()\n",
    "feature_extractor3.eval()\n",
    "SimpleConvmodel.eval()\n",
    "for batch_idx, (data) in enumerate(testloader7):\n",
    "\n",
    "    signal1,signal2,signal3 = data\n",
    "    signal1,signal2,signal3 = Variable(signal1.cuda()), Variable(signal2.cuda()),Variable(signal3.cuda())\n",
    "\n",
    "    feature11,feature21,feature31 = feature_extractor1(signal1)\n",
    "    feature12,feature22,feature32 = feature_extractor2(signal2)\n",
    "    feature13,feature23,feature33 = feature_extractor3(signal3)\n",
    "    feature=torch.cat((signal1,signal2,signal3,feature11,feature21,feature31,feature12,feature22,feature32,feature13,feature23,feature33),dim=1)\n",
    "    out,xview = SimpleConvmodel(feature)   \n",
    "\n",
    "    pred = out.data.max(1, keepdim= True)[1]\n",
    "    predictedv1.append(pred.cpu().detach().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a81321f4-35b9-4e4c-8f96-1846bc879e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 7934.0/7935 (99.9874%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc,predlist,realist=test(feature_extractor1,feature_extractor2,feature_extractor3,backbone,test_loader7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b71c9b66-5148-48b4-afb6-543b07ad0e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=[]\n",
    "# for i in predictedv1:\n",
    "#     predicted.append(i.detach().cpu().numpy()[0][0]+1)\n",
    "\n",
    "textfile = open(\"predict7_model5_train_with123456.txt\", \"w\")\n",
    "for element in predictedv1:\n",
    "    textfile.write(str(element+1) + \"\\n\")\n",
    "textfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82042b-7bd9-421f-9f99-b47ee2804669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e7419-471a-41c1-956a-16149eacde36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9791f-6ae4-45f6-9ded-2e0077c9e175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd2f43-d8a1-4790-8cef-88c37a3217fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31acff-66ec-4a84-b912-74776e577678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5349ef3c-3c72-458c-b6fb-2df033751c1f",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d413b103-9c84-4749-8273-423ecc6ba480",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list1 = []\n",
    "acc_list3 = []\n",
    "\n",
    "\n",
    "feature_extractor1 = Feature_extractor1().to(device)\n",
    "feature_extractor2 = Feature_extractor2().to(device)\n",
    "feature_extractor3 = Feature_extractor3().to(device)\n",
    "SimpleConvmodel = SimpleConv().to(device)\n",
    "\n",
    "best_acc=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f4d40-f22e-4796-8ee5-68d199b7b5b1",
   "metadata": {},
   "source": [
    "### torch save모델 저장할때 꼭 끝에 학습 테스트 indiv숫자 써주세요 예시:total_feature_extractor1_12345_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe1bd1ce-3e33-4219-bac2-796960c5b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def traintest(train___loader,valid___loader,test___loader,triplet___loader,epochs,best_acc):\n",
    "    best_acc=best_acc\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch: {}'.format(epoch))\n",
    "        train(feature_extractor1,feature_extractor2,feature_extractor3,SimpleConvmodel,train___loader,triplet___loader,optimizer, epoch)\n",
    "        acc,_,_=test(feature_extractor1,feature_extractor2,feature_extractor3,SimpleConvmodel,valid___loader)\n",
    "        acc3,_,_=test(feature_extractor1,feature_extractor2,feature_extractor3,SimpleConvmodel,test___loader)\n",
    "\n",
    "        acc_list1.append(acc)\n",
    "        acc_list3.append(acc3)\n",
    "\n",
    "        if acc >= best_acc:\n",
    "            best_model_feature_extractor1 = copy.deepcopy(feature_extractor1.state_dict())\n",
    "            best_model_feature_extractor2 = copy.deepcopy(feature_extractor2.state_dict())\n",
    "            best_model_feature_extractor3 = copy.deepcopy(feature_extractor3.state_dict())\n",
    "            best_model_SimpleConvmodel = copy.deepcopy(SimpleConvmodel.state_dict())\n",
    "\n",
    "            # print('==> best model saved - %d / %.1f'%(epoch, acc))\n",
    "            best_acc=acc\n",
    "\n",
    "    print('Best valid Acc: %.1f' %(best_acc))\n",
    "\n",
    "    feature_extractor1.load_state_dict(best_model_feature_extractor1)\n",
    "    feature_extractor2.load_state_dict(best_model_feature_extractor2)\n",
    "    feature_extractor3.load_state_dict(best_model_feature_extractor3)\n",
    "    SimpleConvmodel.load_state_dict(best_model_SimpleConvmodel)\n",
    "\n",
    "    ##모델 저장할때 끝에 학습 테스트 indiv숫자 써주세요 예시:total_feature_extractor1_12345_6\n",
    "    torch.save(feature_extractor1.state_dict(), 'total_model1_feature_extractor1_123456.pt')\n",
    "    torch.save(feature_extractor2.state_dict(), 'total_model1_feature_extractor2_123456.pt')\n",
    "    torch.save(feature_extractor3.state_dict(), 'total_model1_feature_extractor3_123456.pt')\n",
    "    torch.save(SimpleConvmodel.state_dict(), 'total_model1_SimpleConvmodel_123456.pt')\n",
    "\n",
    "    acc4,predlist,realist=test(feature_extractor1,feature_extractor2,feature_extractor3,SimpleConvmodel,test___loader)\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3588666-7d69-4f97-8c31-ab92e86a08fa",
   "metadata": {},
   "source": [
    "### learning rate 조절시 :위에 모델 선언 다시 업데이트시키지 말고 아래 옵티마이저 숫자만 바꾸고 실행시키고 재학습 하면 이어서 학습됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90a4e69b-3614-4b78-9a3a-467fbf1eec13",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "[3168/23826 (13%)]\t Loss: 0.000956\n",
      "[6368/23826 (27%)]\t Loss: 0.000049\n",
      "[9568/23826 (40%)]\t Loss: 0.000308\n",
      "[12768/23826 (54%)]\t Loss: 0.083233\n",
      "[15968/23826 (67%)]\t Loss: 0.000032\n",
      "[19168/23826 (81%)]\t Loss: 0.000046\n",
      "[22368/23826 (94%)]\t Loss: 0.000035\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 1\n",
      "[3168/23826 (13%)]\t Loss: 0.000038\n",
      "[6368/23826 (27%)]\t Loss: 0.000251\n",
      "[9568/23826 (40%)]\t Loss: 0.000051\n",
      "[12768/23826 (54%)]\t Loss: 0.000087\n",
      "[15968/23826 (67%)]\t Loss: 0.000137\n",
      "[19168/23826 (81%)]\t Loss: 0.000018\n",
      "[22368/23826 (94%)]\t Loss: 0.000961\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 2\n",
      "[3168/23826 (13%)]\t Loss: 0.000080\n",
      "[6368/23826 (27%)]\t Loss: 0.000040\n",
      "[9568/23826 (40%)]\t Loss: 0.000112\n",
      "[12768/23826 (54%)]\t Loss: 0.000026\n",
      "[15968/23826 (67%)]\t Loss: 0.000141\n",
      "[19168/23826 (81%)]\t Loss: 0.000033\n",
      "[22368/23826 (94%)]\t Loss: 0.001068\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 3\n",
      "[3168/23826 (13%)]\t Loss: 0.000126\n",
      "[6368/23826 (27%)]\t Loss: 0.000013\n",
      "[9568/23826 (40%)]\t Loss: 0.000035\n",
      "[12768/23826 (54%)]\t Loss: 0.000055\n",
      "[15968/23826 (67%)]\t Loss: 0.000047\n",
      "[19168/23826 (81%)]\t Loss: 0.000035\n",
      "[22368/23826 (94%)]\t Loss: 0.000036\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 4\n",
      "[3168/23826 (13%)]\t Loss: 0.000013\n",
      "[6368/23826 (27%)]\t Loss: 0.000080\n",
      "[9568/23826 (40%)]\t Loss: 0.000023\n",
      "[12768/23826 (54%)]\t Loss: 0.000065\n",
      "[15968/23826 (67%)]\t Loss: 0.000519\n",
      "[19168/23826 (81%)]\t Loss: 0.000171\n",
      "[22368/23826 (94%)]\t Loss: 0.000661\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 5\n",
      "[3168/23826 (13%)]\t Loss: 0.000014\n",
      "[6368/23826 (27%)]\t Loss: 0.000084\n",
      "[9568/23826 (40%)]\t Loss: 0.000057\n",
      "[12768/23826 (54%)]\t Loss: 0.000024\n",
      "[15968/23826 (67%)]\t Loss: 0.000027\n",
      "[19168/23826 (81%)]\t Loss: 0.000009\n",
      "[22368/23826 (94%)]\t Loss: 0.000041\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 6\n",
      "[3168/23826 (13%)]\t Loss: 0.000274\n",
      "[6368/23826 (27%)]\t Loss: 0.000008\n",
      "[9568/23826 (40%)]\t Loss: 0.000232\n",
      "[12768/23826 (54%)]\t Loss: 0.000010\n",
      "[15968/23826 (67%)]\t Loss: 0.000129\n",
      "[19168/23826 (81%)]\t Loss: 0.000425\n",
      "[22368/23826 (94%)]\t Loss: 0.000015\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 7\n",
      "[3168/23826 (13%)]\t Loss: 0.000009\n",
      "[6368/23826 (27%)]\t Loss: 0.000006\n",
      "[9568/23826 (40%)]\t Loss: 0.000015\n",
      "[12768/23826 (54%)]\t Loss: 0.000022\n",
      "[15968/23826 (67%)]\t Loss: 0.000107\n",
      "[19168/23826 (81%)]\t Loss: 0.000010\n",
      "[22368/23826 (94%)]\t Loss: 0.001539\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 8\n",
      "[3168/23826 (13%)]\t Loss: 0.000138\n",
      "[6368/23826 (27%)]\t Loss: 0.000028\n",
      "[9568/23826 (40%)]\t Loss: 0.000079\n",
      "[12768/23826 (54%)]\t Loss: 0.000019\n",
      "[15968/23826 (67%)]\t Loss: 0.000038\n",
      "[19168/23826 (81%)]\t Loss: 0.000006\n",
      "[22368/23826 (94%)]\t Loss: 0.000046\n",
      "\n",
      "Accuracy: 5949.0/5957 (99.8657%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 9\n",
      "[3168/23826 (13%)]\t Loss: 0.000063\n",
      "[6368/23826 (27%)]\t Loss: 0.000070\n",
      "[9568/23826 (40%)]\t Loss: 0.000029\n",
      "[12768/23826 (54%)]\t Loss: 0.000019\n",
      "[15968/23826 (67%)]\t Loss: 0.000059\n",
      "[19168/23826 (81%)]\t Loss: 0.000073\n",
      "[22368/23826 (94%)]\t Loss: 0.000020\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 10\n",
      "[3168/23826 (13%)]\t Loss: 0.000027\n",
      "[6368/23826 (27%)]\t Loss: 0.000019\n",
      "[9568/23826 (40%)]\t Loss: 0.000027\n",
      "[12768/23826 (54%)]\t Loss: 0.000049\n",
      "[15968/23826 (67%)]\t Loss: 0.000050\n",
      "[19168/23826 (81%)]\t Loss: 0.000024\n",
      "[22368/23826 (94%)]\t Loss: 0.000062\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 11\n",
      "[3168/23826 (13%)]\t Loss: 0.000014\n",
      "[6368/23826 (27%)]\t Loss: 0.000022\n",
      "[9568/23826 (40%)]\t Loss: 0.000007\n",
      "[12768/23826 (54%)]\t Loss: 0.000798\n",
      "[15968/23826 (67%)]\t Loss: 0.000042\n",
      "[19168/23826 (81%)]\t Loss: 0.004763\n",
      "[22368/23826 (94%)]\t Loss: 0.000009\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 12\n",
      "[3168/23826 (13%)]\t Loss: 0.000023\n",
      "[6368/23826 (27%)]\t Loss: 0.001671\n",
      "[9568/23826 (40%)]\t Loss: 0.000013\n",
      "[12768/23826 (54%)]\t Loss: 0.000033\n",
      "[15968/23826 (67%)]\t Loss: 0.000049\n",
      "[19168/23826 (81%)]\t Loss: 0.000021\n",
      "[22368/23826 (94%)]\t Loss: 0.000019\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 13\n",
      "[3168/23826 (13%)]\t Loss: 0.000034\n",
      "[6368/23826 (27%)]\t Loss: 0.000077\n",
      "[9568/23826 (40%)]\t Loss: 0.000207\n",
      "[12768/23826 (54%)]\t Loss: 0.000025\n",
      "[15968/23826 (67%)]\t Loss: 0.000032\n",
      "[19168/23826 (81%)]\t Loss: 0.000030\n",
      "[22368/23826 (94%)]\t Loss: 0.000022\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 14\n",
      "[3168/23826 (13%)]\t Loss: 0.000412\n",
      "[6368/23826 (27%)]\t Loss: 0.000010\n",
      "[9568/23826 (40%)]\t Loss: 0.000016\n",
      "[12768/23826 (54%)]\t Loss: 0.000692\n",
      "[15968/23826 (67%)]\t Loss: 0.000018\n",
      "[19168/23826 (81%)]\t Loss: 0.000029\n",
      "[22368/23826 (94%)]\t Loss: 0.000031\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 15\n",
      "[3168/23826 (13%)]\t Loss: 0.000006\n",
      "[6368/23826 (27%)]\t Loss: 0.000012\n",
      "[9568/23826 (40%)]\t Loss: 0.000019\n",
      "[12768/23826 (54%)]\t Loss: 0.000250\n",
      "[15968/23826 (67%)]\t Loss: 0.000058\n",
      "[19168/23826 (81%)]\t Loss: 0.000012\n",
      "[22368/23826 (94%)]\t Loss: 0.000031\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 16\n",
      "[3168/23826 (13%)]\t Loss: 0.000286\n",
      "[6368/23826 (27%)]\t Loss: 0.000016\n",
      "[9568/23826 (40%)]\t Loss: 0.000011\n",
      "[12768/23826 (54%)]\t Loss: 0.000007\n",
      "[15968/23826 (67%)]\t Loss: 0.001554\n",
      "[19168/23826 (81%)]\t Loss: 0.000007\n",
      "[22368/23826 (94%)]\t Loss: 0.000038\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 17\n",
      "[3168/23826 (13%)]\t Loss: 0.000028\n",
      "[6368/23826 (27%)]\t Loss: 0.000042\n",
      "[9568/23826 (40%)]\t Loss: 0.000016\n",
      "[12768/23826 (54%)]\t Loss: 0.000580\n",
      "[15968/23826 (67%)]\t Loss: 0.000009\n",
      "[19168/23826 (81%)]\t Loss: 0.000183\n",
      "[22368/23826 (94%)]\t Loss: 0.000010\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 18\n",
      "[3168/23826 (13%)]\t Loss: 0.000003\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000025\n",
      "[12768/23826 (54%)]\t Loss: 0.000042\n",
      "[15968/23826 (67%)]\t Loss: 0.000013\n",
      "[19168/23826 (81%)]\t Loss: 0.000011\n",
      "[22368/23826 (94%)]\t Loss: 0.000007\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 19\n",
      "[3168/23826 (13%)]\t Loss: 0.000003\n",
      "[6368/23826 (27%)]\t Loss: 0.000007\n",
      "[9568/23826 (40%)]\t Loss: 0.000101\n",
      "[12768/23826 (54%)]\t Loss: 0.000009\n",
      "[15968/23826 (67%)]\t Loss: 0.000170\n",
      "[19168/23826 (81%)]\t Loss: 0.000221\n",
      "[22368/23826 (94%)]\t Loss: 0.000950\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Best valid Acc: 99.9\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예시  첫번째 0.0001학습 50번에포크\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "        {'params': feature_extractor1.parameters()},\n",
    "        {'params': feature_extractor2.parameters()},\n",
    "        {'params': feature_extractor3.parameters()},\n",
    "        {'params': SimpleConvmodel.parameters()},    \n",
    "        ], lr= 0.0001)\n",
    "best_accc=traintest(train_loader123456,valid_loader123456,test_loader123456,triplet_loader123456,20,best_acc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccf7a19b-7e49-47d7-8f0a-01dd16e44f89",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "[3168/23826 (13%)]\t Loss: 0.000014\n",
      "[6368/23826 (27%)]\t Loss: 0.000040\n",
      "[9568/23826 (40%)]\t Loss: 0.000027\n",
      "[12768/23826 (54%)]\t Loss: 0.000029\n",
      "[15968/23826 (67%)]\t Loss: 0.000100\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000003\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 1\n",
      "[3168/23826 (13%)]\t Loss: 0.000005\n",
      "[6368/23826 (27%)]\t Loss: 0.000003\n",
      "[9568/23826 (40%)]\t Loss: 0.000009\n",
      "[12768/23826 (54%)]\t Loss: 0.000003\n",
      "[15968/23826 (67%)]\t Loss: 0.000060\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000006\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 2\n",
      "[3168/23826 (13%)]\t Loss: 0.000011\n",
      "[6368/23826 (27%)]\t Loss: 0.000006\n",
      "[9568/23826 (40%)]\t Loss: 0.000003\n",
      "[12768/23826 (54%)]\t Loss: 0.000003\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000005\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 3\n",
      "[3168/23826 (13%)]\t Loss: 0.000005\n",
      "[6368/23826 (27%)]\t Loss: 0.000006\n",
      "[9568/23826 (40%)]\t Loss: 0.000008\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000006\n",
      "[19168/23826 (81%)]\t Loss: 0.000008\n",
      "[22368/23826 (94%)]\t Loss: 0.000010\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 4\n",
      "[3168/23826 (13%)]\t Loss: 0.000045\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000004\n",
      "[12768/23826 (54%)]\t Loss: 0.000003\n",
      "[15968/23826 (67%)]\t Loss: 0.000009\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000005\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 5\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000006\n",
      "[9568/23826 (40%)]\t Loss: 0.000002\n",
      "[12768/23826 (54%)]\t Loss: 0.000002\n",
      "[15968/23826 (67%)]\t Loss: 0.000002\n",
      "[19168/23826 (81%)]\t Loss: 0.000007\n",
      "[22368/23826 (94%)]\t Loss: 0.000058\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 6\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000003\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000032\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 7\n",
      "[3168/23826 (13%)]\t Loss: 0.000003\n",
      "[6368/23826 (27%)]\t Loss: 0.000028\n",
      "[9568/23826 (40%)]\t Loss: 0.001527\n",
      "[12768/23826 (54%)]\t Loss: 0.000002\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 8\n",
      "[3168/23826 (13%)]\t Loss: 0.000005\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000002\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000017\n",
      "[22368/23826 (94%)]\t Loss: 0.000005\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 9\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000002\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000002\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 10\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000011\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 11\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000000\n",
      "[9568/23826 (40%)]\t Loss: 0.000002\n",
      "[12768/23826 (54%)]\t Loss: 0.000004\n",
      "[15968/23826 (67%)]\t Loss: 0.000004\n",
      "[19168/23826 (81%)]\t Loss: 0.000006\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 12\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000009\n",
      "[12768/23826 (54%)]\t Loss: 0.000004\n",
      "[15968/23826 (67%)]\t Loss: 0.000004\n",
      "[19168/23826 (81%)]\t Loss: 0.000004\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 13\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000002\n",
      "[12768/23826 (54%)]\t Loss: 0.000003\n",
      "[15968/23826 (67%)]\t Loss: 0.000003\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 14\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000003\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000005\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 15\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000021\n",
      "[9568/23826 (40%)]\t Loss: 0.000010\n",
      "[12768/23826 (54%)]\t Loss: 0.000003\n",
      "[15968/23826 (67%)]\t Loss: 0.000004\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000004\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 16\n",
      "[3168/23826 (13%)]\t Loss: 0.000004\n",
      "[6368/23826 (27%)]\t Loss: 0.000028\n",
      "[9568/23826 (40%)]\t Loss: 0.000003\n",
      "[12768/23826 (54%)]\t Loss: 0.000013\n",
      "[15968/23826 (67%)]\t Loss: 0.000002\n",
      "[19168/23826 (81%)]\t Loss: 0.000007\n",
      "[22368/23826 (94%)]\t Loss: 0.000614\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 17\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000003\n",
      "[9568/23826 (40%)]\t Loss: 0.000002\n",
      "[12768/23826 (54%)]\t Loss: 0.000002\n",
      "[15968/23826 (67%)]\t Loss: 0.000003\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000007\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 18\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000005\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000003\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000017\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 19\n",
      "[3168/23826 (13%)]\t Loss: 0.000000\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000002\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000005\n",
      "[19168/23826 (81%)]\t Loss: 0.000003\n",
      "[22368/23826 (94%)]\t Loss: 0.000009\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 20\n",
      "[3168/23826 (13%)]\t Loss: 0.000013\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000000\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000032\n",
      "[19168/23826 (81%)]\t Loss: 0.000000\n",
      "[22368/23826 (94%)]\t Loss: 0.000007\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 21\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000005\n",
      "[9568/23826 (40%)]\t Loss: 0.000003\n",
      "[12768/23826 (54%)]\t Loss: 0.000022\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000000\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 22\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000003\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000003\n",
      "[15968/23826 (67%)]\t Loss: 0.000002\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000002\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 23\n",
      "[3168/23826 (13%)]\t Loss: 0.000003\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000002\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000003\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 24\n",
      "[3168/23826 (13%)]\t Loss: 0.000009\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000002\n",
      "[12768/23826 (54%)]\t Loss: 0.000000\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 25\n",
      "[3168/23826 (13%)]\t Loss: 0.000027\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000005\n",
      "[12768/23826 (54%)]\t Loss: 0.000008\n",
      "[15968/23826 (67%)]\t Loss: 0.000005\n",
      "[19168/23826 (81%)]\t Loss: 0.000017\n",
      "[22368/23826 (94%)]\t Loss: 0.000000\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 26\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000000\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000002\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000003\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 27\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000000\n",
      "[12768/23826 (54%)]\t Loss: 0.000003\n",
      "[15968/23826 (67%)]\t Loss: 0.000005\n",
      "[19168/23826 (81%)]\t Loss: 0.000000\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 28\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000017\n",
      "[12768/23826 (54%)]\t Loss: 0.000014\n",
      "[15968/23826 (67%)]\t Loss: 0.000008\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000005\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 29\n",
      "[3168/23826 (13%)]\t Loss: 0.000005\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000022\n",
      "[19168/23826 (81%)]\t Loss: 0.000089\n",
      "[22368/23826 (94%)]\t Loss: 0.000003\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 30\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000019\n",
      "[9568/23826 (40%)]\t Loss: 0.000000\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000000\n",
      "[22368/23826 (94%)]\t Loss: 0.000000\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 31\n",
      "[3168/23826 (13%)]\t Loss: 0.000000\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000002\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000006\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 32\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000000\n",
      "[9568/23826 (40%)]\t Loss: 0.000022\n",
      "[12768/23826 (54%)]\t Loss: 0.000002\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000008\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 33\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000000\n",
      "[19168/23826 (81%)]\t Loss: 0.000000\n",
      "[22368/23826 (94%)]\t Loss: 0.000004\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 34\n",
      "[3168/23826 (13%)]\t Loss: 0.000000\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000002\n",
      "[12768/23826 (54%)]\t Loss: 0.000000\n",
      "[15968/23826 (67%)]\t Loss: 0.000003\n",
      "[19168/23826 (81%)]\t Loss: 0.000003\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 35\n",
      "[3168/23826 (13%)]\t Loss: 0.000000\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000007\n",
      "[12768/23826 (54%)]\t Loss: 0.000003\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 36\n",
      "[3168/23826 (13%)]\t Loss: 0.000000\n",
      "[6368/23826 (27%)]\t Loss: 0.000000\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000003\n",
      "[22368/23826 (94%)]\t Loss: 0.000003\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 37\n",
      "[3168/23826 (13%)]\t Loss: 0.000005\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000000\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000000\n",
      "[19168/23826 (81%)]\t Loss: 0.000000\n",
      "[22368/23826 (94%)]\t Loss: 0.000002\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 38\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000007\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000000\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000002\n",
      "[22368/23826 (94%)]\t Loss: 0.000000\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 39\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000003\n",
      "[15968/23826 (67%)]\t Loss: 0.000000\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 40\n",
      "[3168/23826 (13%)]\t Loss: 0.000002\n",
      "[6368/23826 (27%)]\t Loss: 0.000003\n",
      "[9568/23826 (40%)]\t Loss: 0.000002\n",
      "[12768/23826 (54%)]\t Loss: 0.000008\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000000\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 41\n",
      "[3168/23826 (13%)]\t Loss: 0.000000\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000004\n",
      "[22368/23826 (94%)]\t Loss: 0.000000\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 42\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000000\n",
      "[12768/23826 (54%)]\t Loss: 0.000030\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000003\n",
      "[22368/23826 (94%)]\t Loss: 0.000000\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 43\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000000\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000000\n",
      "[15968/23826 (67%)]\t Loss: 0.000003\n",
      "[19168/23826 (81%)]\t Loss: 0.000000\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 44\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000001\n",
      "[9568/23826 (40%)]\t Loss: 0.000000\n",
      "[12768/23826 (54%)]\t Loss: 0.000000\n",
      "[15968/23826 (67%)]\t Loss: 0.000003\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 45\n",
      "[3168/23826 (13%)]\t Loss: 0.000000\n",
      "[6368/23826 (27%)]\t Loss: 0.000000\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000000\n",
      "[19168/23826 (81%)]\t Loss: 0.000000\n",
      "[22368/23826 (94%)]\t Loss: 0.000000\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 46\n",
      "[3168/23826 (13%)]\t Loss: 0.000001\n",
      "[6368/23826 (27%)]\t Loss: 0.000006\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000000\n",
      "[15968/23826 (67%)]\t Loss: 0.000000\n",
      "[19168/23826 (81%)]\t Loss: 0.000000\n",
      "[22368/23826 (94%)]\t Loss: 0.000001\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 47\n",
      "[3168/23826 (13%)]\t Loss: 0.000027\n",
      "[6368/23826 (27%)]\t Loss: 0.000004\n",
      "[9568/23826 (40%)]\t Loss: 0.000013\n",
      "[12768/23826 (54%)]\t Loss: 0.000009\n",
      "[15968/23826 (67%)]\t Loss: 0.000000\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000005\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 48\n",
      "[3168/23826 (13%)]\t Loss: 0.000000\n",
      "[6368/23826 (27%)]\t Loss: 0.000002\n",
      "[9568/23826 (40%)]\t Loss: 0.000000\n",
      "[12768/23826 (54%)]\t Loss: 0.000000\n",
      "[15968/23826 (67%)]\t Loss: 0.000001\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000003\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Epoch: 49\n",
      "[3168/23826 (13%)]\t Loss: 0.000006\n",
      "[6368/23826 (27%)]\t Loss: 0.000000\n",
      "[9568/23826 (40%)]\t Loss: 0.000001\n",
      "[12768/23826 (54%)]\t Loss: 0.000001\n",
      "[15968/23826 (67%)]\t Loss: 0.000000\n",
      "[19168/23826 (81%)]\t Loss: 0.000001\n",
      "[22368/23826 (94%)]\t Loss: 0.000005\n",
      "\n",
      "Accuracy: 5952.0/5957 (99.9161%)\n",
      "\n",
      "\n",
      "Accuracy: 7446.0/7446 (100.0000%)\n",
      "\n",
      "Best valid Acc: 100.0\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'best_model_feature_extractor1' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16716\\1380820148.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;33m{\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSimpleConvmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         ], lr= 0.00001)\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtraintest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader123456\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_loader123456\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_loader123456\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtriplet_loader123456\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16716\\1927358602.py\u001b[0m in \u001b[0;36mtraintest\u001b[1;34m(train___loader, valid___loader, test___loader, triplet___loader, epochs, best_acc)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best valid Acc: %.1f'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mfeature_extractor1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model_feature_extractor1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mfeature_extractor2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model_feature_extractor2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mfeature_extractor3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model_feature_extractor3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'best_model_feature_extractor1' referenced before assignment"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam([\n",
    "        {'params': feature_extractor1.parameters()},\n",
    "        {'params': feature_extractor2.parameters()},\n",
    "        {'params': feature_extractor3.parameters()},\n",
    "        {'params': SimpleConvmodel.parameters()},    \n",
    "        ], lr= 0.00001)\n",
    "traintest(train_loader123456,valid_loader123456,test_loader123456,triplet_loader123456,50,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6af59276-eea3-44ec-aeed-00536f004bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor1.load_state_dict(best_model_feature_extractor1)\n",
    "# feature_extractor2.load_state_dict(best_model_feature_extractor2)\n",
    "# feature_extractor3.load_state_dict(best_model_feature_extractor3)\n",
    "# SimpleConvmodel.load_state_dict(best_model_SimpleConvmodel)\n",
    "\n",
    "##모델 저장할때 끝에 학습 테스트 indiv숫자 써주세요 예시:total_feature_extractor1_12345_6\n",
    "torch.save(feature_extractor1.state_dict(), 'total_model1_feature_extractor1_123456.pt')\n",
    "torch.save(feature_extractor2.state_dict(), 'total_model1_feature_extractor2_123456.pt')\n",
    "torch.save(feature_extractor3.state_dict(), 'total_model1_feature_extractor3_123456.pt')\n",
    "torch.save(SimpleConvmodel.state_dict(), 'total_model1_SimpleConvmodel_123456.pt')\n",
    "\n",
    "# acc4,predlist,realist=test(feature_extractor1,feature_extractor2,feature_extractor3,SimpleConvmodel,test___loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc76f3-0594-4766-8e2a-2aa7e25e1336",
   "metadata": {},
   "source": [
    "## validation set 몇퍼인지 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7b7edb3-c62e-40df-aa48-34b278a9cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "predlist7=test2(feature_extractor1,feature_extractor2,feature_extractor3,SimpleConvmodel,testloader7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dbc51d27-9814-434f-9fdc-e5f18e0fcfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predlist7=test2(feature_extractor1,feature_extractor2,feature_extractor3,SimpleConvmodel,testloader7)\n",
    "predictedv1=[]\n",
    "for i in predlist7:\n",
    "    predictedv1.append(i.detach().cpu().numpy()[0][0]+1)\n",
    "predictedv2=[]\n",
    "for i in predlist8:\n",
    "    predictedv2.append(i.detach().cpu().numpy()[0][0]+1)\n",
    "textfile = open(\"predict7_model1_train_with123456.txt\", \"w\")\n",
    "for element in predictedv1:\n",
    "    textfile.write(str(element) + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436cf457-d8c3-404f-a039-3d8c9338cae2",
   "metadata": {},
   "source": [
    "### 제목에 몇번 indiv train->test 해서 나온 결과물인지 써주세요  예시 :predict7_train12345test6.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fb54981-198a-44f3-8a70-410a9e8ac450",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"predict7_model1_train_with123456.txt\", \"w\")\n",
    "for element in predictedv1:\n",
    "    textfile.write(str(element) + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a12a83-1bd4-486b-9166-6c918c3436ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
